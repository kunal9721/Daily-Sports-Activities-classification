{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4589788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "741aad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pcafilewlabels.csv', header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319f51b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = df.iloc[:,40:42]\n",
    "X2 = X2.apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "085bbaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.556408</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.000724</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>-0.000199</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000836</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>-0.001576</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.555708</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>-0.000703</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>0.001231</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>0.002711</td>\n",
       "      <td>0.012504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.001139</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>-0.002051</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.556088</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000715</td>\n",
       "      <td>-0.000728</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>-0.000215</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.012733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>-0.000898</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>-0.001549</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.555757</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>-0.000714</td>\n",
       "      <td>0.001223</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.012477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000782</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.002836</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.555139</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000681</td>\n",
       "      <td>-0.000712</td>\n",
       "      <td>0.001199</td>\n",
       "      <td>-0.000148</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.012260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>-0.001159</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>-0.001825</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0 -0.556408  0.000028  0.000418  0.000036 -0.000713 -0.000724  0.001234   \n",
       "1 -0.555708  0.000018  0.000419  0.000021 -0.000703 -0.000718  0.001231   \n",
       "2 -0.556088  0.000028  0.000417  0.000039 -0.000715 -0.000728  0.001247   \n",
       "3 -0.555757  0.000019  0.000425  0.000024 -0.000701 -0.000714  0.001223   \n",
       "4 -0.555139  0.000005  0.000428  0.000008 -0.000681 -0.000712  0.001199   \n",
       "\n",
       "         7         8         9   ...        32        33        34        35  \\\n",
       "0 -0.000199  0.002731  0.012509  ...  0.000281  0.000153 -0.000026 -0.000836   \n",
       "1 -0.000156  0.002711  0.012504  ...  0.000117  0.000206  0.000019 -0.001139   \n",
       "2 -0.000215  0.002794  0.012733  ...  0.000329  0.000222  0.000167 -0.000898   \n",
       "3 -0.000171  0.002714  0.012477  ...  0.000212  0.000121 -0.000067 -0.000782   \n",
       "4 -0.000148  0.002652  0.012260  ... -0.000058  0.000433  0.000297 -0.001159   \n",
       "\n",
       "         36        37        38        39  40  41  \n",
       "0  0.003419  0.002796  0.000497 -0.001576   0   0  \n",
       "1  0.003907  0.003582  0.000851 -0.002051   0   0  \n",
       "2  0.003403  0.002881  0.000560 -0.001549   0   0  \n",
       "3  0.003404  0.002836  0.000426 -0.001647   0   0  \n",
       "4  0.003651  0.003394  0.000734 -0.001825   0   0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = df.iloc[:,0:40].join(X2)\n",
    "X_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6d410d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_2.iloc[:,0:40].values\n",
    "y = X_2[41].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b7672bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 451)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aacf456",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-3aaf935e6aec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e748a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(X_train)\n",
    "X_test = torch.from_numpy(X_test)\n",
    "y_train = torch.from_numpy(y_train)\n",
    "y_test = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5832dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.long()\n",
    "y_test = y_test.long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf74f829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b0270c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6840, 40]),\n",
       " torch.Size([2280, 40]),\n",
       " torch.Size([6840]),\n",
       " torch.Size([2280]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72f69b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_samples = TensorDataset(X_train, y_train)\n",
    "test_samples = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(training_samples, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(test_samples, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c3c803",
   "metadata": {},
   "source": [
    "With Adam Optimizer.\n",
    "Optimizer : Adam\n",
    "Learning Rate : 1e-2\n",
    "Number of Hidden layers : 1\n",
    "Number of neurons in hidden layers : 100\n",
    "Activation function(s) used : ReLU\n",
    "Batch size : 64\n",
    "Epochs : 500\n",
    "Final loss of the last batch / neuron : 0.297\n",
    "Accuracy of the model : 0.8951"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0ccb18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100,  loss: 0.416\n",
      "Epoch : 200,  loss: 0.304\n",
      "Epoch : 300,  loss: 0.258\n",
      "Epoch : 400,  loss: 0.200\n",
      "Epoch : 500,  loss: 0.204\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        \"\"\"\n",
    "        In the constructor we construct three nn.Linear instances that we will use\n",
    "        in the forward pass.\n",
    "        \"\"\"\n",
    "\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.input_linear = torch.nn.Linear(D_in, H)\n",
    "        self.middle_linear = torch.nn.Linear(H, H)\n",
    "        self.output_linear = torch.nn.Linear(H, D_out)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 0, 1, 2, or 3\n",
    "        and reuse the middle_linear Module that many times to compute hidden layer\n",
    "        representations.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same Module many\n",
    "        times when defining a computational graph. This is a big improvement from Lua\n",
    "        Torch, where each Module could be used only once.\n",
    "        \"\"\"\n",
    "        h_relu = self.input_linear(x).clamp(min=0)\n",
    "        for _ in range(np.random.randint(0, 3)):\n",
    "            h_relu = self.middle_linear(h_relu).clamp(min=0)\n",
    "        y_pred = self.output_linear(h_relu)\n",
    "        return y_pred\n",
    "      \n",
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 64, 40, 100, 19\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet(D_in, H, D_out)\n",
    "# making our model operate at double precision.\n",
    "model = model.double()\n",
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "# since it is multiclass classification problem, we are using CrossEntropyLoss, instead of MSEloss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "learning_rate = 1e-2 # alpha\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # Adam optimizers\n",
    "\n",
    "for epoch in range(500):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print('Epoch : %d,  loss: %.3f' %\n",
    "              (epoch + 1, running_loss / 64))\n",
    "    running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7beb9aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-25-de52482e4f77>:2: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  X_test_var = Variable(X_test, volatile=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9114035087719298"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass it through the model\n",
    "X_test_var = Variable(X_test, volatile=True)\n",
    "scores = model(X_test_var)\n",
    "_, preds = torch.max(scores, dim=1)\n",
    "\n",
    "accuracy_score(preds.data.numpy(), y_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13757983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7915f44e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
